{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define transforms for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # Adding color jitter\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load pre-trained ResNet101 model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "resnet = models.resnet101(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the pre-trained ResNet101 model\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes in FashionMNIST (10)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the list of optimizers to use\n",
    "optimizers = [optim.Adam(resnet.parameters()),\n",
    "              optim.Adagrad(resnet.parameters()),\n",
    "              optim.RMSprop(resnet.parameters())]\n",
    "\n",
    "# Lists to store training statistics\n",
    "train_losses = [[] for _ in range(len(optimizers))]\n",
    "train_accuracy = [[] for _ in range(len(optimizers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    print(f\"Training with optimizer: {type(optimizer).__name__}\")\n",
    "    for epoch in range(1):  # Train for 1 epochs\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(trainloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_losses[i].append(running_loss / len(trainloader))\n",
    "        train_accuracy[i].append(100 * correct / total)\n",
    "        print(f\"Epoch [{epoch + 1}/5], Loss: {train_losses[i][-1]:.4f}, Accuracy: {train_accuracy[i][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot training loss and accuracy curves\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(len(optimizers)):\n",
    "#     plt.subplot(2, len(optimizers)//2, i+1)\n",
    "#     plt.plot(train_losses[i], label='Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Training Loss')\n",
    "#     plt.title(f'Training Loss with {type(optimizers[i]).__name__}')\n",
    "#     plt.legend()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(len(optimizers)):\n",
    "#     plt.subplot(2, len(optimizers)//2, i+1)\n",
    "#     plt.plot(train_accuracy[i], label='Accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Training Accuracy')\n",
    "#     plt.title(f'Training Accuracy with {type(optimizers[i]).__name__}')\n",
    "#     plt.legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming train_losses is a list of lists containing training losses for each optimizer\n",
    "# train_losses = [adam_losses, adagrad_losses, adadelta_losses, rmsprop_losses]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "num_optimizers = len(train_losses)\n",
    "\n",
    "for i in range(num_optimizers):\n",
    "    plt.subplot(2, (num_optimizers + 1) // 2, i + 1)  # Adjusted to ensure integer number of subplots\n",
    "    plt.plot(train_losses[i], label='Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss - {optimizers[i]}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in testloader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         outputs = resnet(images)\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "# print(f\"Top-5 Test Accuracy: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "import torch\n",
    "\n",
    "# Assuming testloader is the DataLoader for the FashionMNIST test set\n",
    "correct = 0\n",
    "total = 0\n",
    "top5_correct = 0\n",
    "\n",
    "# Set model to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.topk(outputs, 5, dim=1)  # Get top-5 predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.view(-1, 1)).sum().item()\n",
    "        for i in range(labels.size(0)):\n",
    "            if labels[i] in predicted[i]:\n",
    "                top5_correct += 1\n",
    "\n",
    "print(f'Top-5 Test Accuracy: {100 * top5_correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
